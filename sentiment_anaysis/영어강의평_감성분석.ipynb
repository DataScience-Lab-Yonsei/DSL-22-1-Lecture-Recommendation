{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"영어강의평_감성분석.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOF3R8GCEezfHOnmZm7hPIx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 데이터 정제"],"metadata":{"id":"iMPqbNodrAsZ"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"EGxGzWZzrAbt","executionInfo":{"status":"ok","timestamp":1649849191844,"user_tz":-540,"elapsed":927,"user":{"displayName":"손예진","userId":"04844610137115979669"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mnvjJ6BrF0W","executionInfo":{"status":"ok","timestamp":1649849272109,"user_tz":-540,"elapsed":23074,"user":{"displayName":"손예진","userId":"04844610137115979669"}},"outputId":"6872123c-be0b-4bf9-e5dd-9423cb9057b7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["df = pd.read_excel(\"/content/drive/Shareddrives/NLP모델링/코드 연습/예진/강의평_eng.xlsx\")"],"metadata":{"id":"fnZwvrCarEgk","executionInfo":{"status":"ok","timestamp":1649849283500,"user_tz":-540,"elapsed":10304,"user":{"displayName":"손예진","userId":"04844610137115979669"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df= df.rename(columns={'Unnamed: 9':'eng'})"],"metadata":{"id":"bp0kp8v7rH3j","executionInfo":{"status":"ok","timestamp":1649849283501,"user_tz":-540,"elapsed":5,"user":{"displayName":"손예진","userId":"04844610137115979669"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import re\n","df['eng'] = df['eng'].apply( lambda x : re.sub(\"[^a-zA-Z]\", \" \", x) )"],"metadata":{"id":"2xHV3kjnrMZb","executionInfo":{"status":"ok","timestamp":1649849283501,"user_tz":-540,"elapsed":4,"user":{"displayName":"손예진","userId":"04844610137115979669"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["dfl =df\n","dfl=dfl[['학정번호', '강의명/교수명',\n","       '강의명', '교수명', '유의사항', '별점', '수강시기', '강의평', 'eng']]"],"metadata":{"id":"-GaRq_w8rX1F","executionInfo":{"status":"ok","timestamp":1649849283501,"user_tz":-540,"elapsed":3,"user":{"displayName":"손예진","userId":"04844610137115979669"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## 비지도학습 기반 감성 분석(lexicon을 활용한 감성분석)"],"metadata":{"id":"-FSrY-_VrgCX"}},{"cell_type":"markdown","source":["## sentiwordnet 이용"],"metadata":{"id":"zIvVY-CorkMJ"}},{"cell_type":"code","source":["import nltk\n","nltk.download('all')"],"metadata":{"id":"pDG8JSZlriEd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.corpus import wordnet as wn\n","import nltk\n","from nltk.corpus import sentiwordnet as swn"],"metadata":{"id":"kAjIzCClriCI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 간단한 NTLK PennTreebank Tag를 기반으로 WordNet기반의 품사 Tag로 변환\n","def penn_to_wn(tag):\n","    if tag.startswith('J'):\n","        return wn.ADJ\n","    elif tag.startswith('N'):\n","        return wn.NOUN\n","    elif tag.startswith('R'):\n","        return wn.ADV\n","    elif tag.startswith('V'):\n","        return wn.VERB\n","    return "],"metadata":{"id":"E4QrnxEAriAB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","from nltk import sent_tokenize, word_tokenize, pos_tag"],"metadata":{"id":"Ii5IxM_drh9x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def swn_polarity(text):\n","    # 감성 지수 초기화 \n","    sentiment = 0.0\n","    tokens_count = 0\n","    li=[] #감성을 유발한 lemma(어근)담기\n","    lemmatizer = WordNetLemmatizer()\n","    raw_sentences = sent_tokenize(text)\n","    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산 \n","    for raw_sentence in raw_sentences:\n","        # NTLK 기반의 품사 태깅 문장 추출  \n","        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n","        for word , tag in tagged_sentence:\n","            \n","            # WordNet 기반 품사 태깅과 어근 추출\n","            wn_tag = penn_to_wn(tag)\n","            if wn_tag not in (wn.NOUN , wn.ADJ, wn.ADV):\n","                continue                   \n","            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n","            if not lemma:\n","                continue\n","            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성. \n","            li.append(lemma)\n","            synsets = wn.synsets(lemma , pos=wn_tag)\n","            if not synsets:\n","                continue\n","            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n","            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산. \n","            synset = synsets[0]\n","            swn_synset = swn.senti_synset(synset.name())\n","            \n","            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())           \n","            tokens_count += 1\n","    \n","    if not tokens_count:\n","        return 0\n","    \n","    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n","    if sentiment >= 0 :\n","        return 1,li\n","    \n","    return 0,li"],"metadata":{"id":"NbwJjJNcroyq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## vader이용"],"metadata":{"id":"k2A78RLkrvXD"}},{"cell_type":"code","source":["from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","\n","senti_analyzer = SentimentIntensityAnalyzer()\n","senti_scores = senti_analyzer.polarity_scores(dfl['eng'][1])\n","print(senti_scores)\n","#the compound score is the sum of positive, negative & neutral scores\n","# which is then normalized between -1(most extreme negative) and +1 (most extreme positive)."],"metadata":{"id":"1SAHa7unrowr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# threshold 기준\n","threshold_l, threshold_u   \n"," 0: negative 1: positive 0.5: neutral  \n","\n","여러 번의 실험결과 0,0.1이 최적에 가까웠다."],"metadata":{"id":"ajQvB49nr64O"}},{"cell_type":"code","source":["def vader_polarity(review,threshold_l = 0.0, threshold_u = 0.1 ):\n","    analyzer = SentimentIntensityAnalyzer()\n","    scores = analyzer.polarity_scores(review)\n","    \n","    # compound 값에 기반하여 threshold 입력값보다 크면 1, 그렇지 않으면 0을 반환 \n","    agg_score = scores['compound']\n","    if agg_score >= threshold_u:\n","      final_sentiment = 1\n","    elif agg_score <= threshold_l:\n","       final_sentiment = 0\n","    else:\n","       final_sentiment = 0.5\n","    return final_sentiment"],"metadata":{"id":"LpFiLlO3ryQm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dfl['vader_preds'] = dfl['eng'].apply( lambda x : vader_polarity(x, 0, 0.1) )"],"metadata":{"id":"VVlcY92eryO3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# word2vec 임베딩 : 성적, 로드, 강의력, 교수성향에 대한 각각의 라벨링을 위해 각 주제와 관련이 있는 단어를 추출하자.\n","\n","1. sentiwordnet에서 뽑힌 모든 단어를 unique하게 리스트업하고, 빈도수 계산 : trigger(counter)\n","2. 영어강의평 word2vec 훈련\n","3. 성적, 로드, 강의력, 교수성향과 관련된 단어 추출\n","4. trigger list들에 대해 stop word 제거하고 남은 단어들에 대해 3번과 일치하는 값이 존재하면 Y\n","5. Y로 선택된 값은 감성분석 결과를 해당 카테고리의 값으로 부여\n","6. 최종 점수 부여: 직접 라벨링한 것 0.3 각각을 라벨링한 것 0.7로 가중평균 구한 열 추가\n","(만약 직접 라벨링이 없으면 직접 라벨링한 값으로 대체하되, 평점이 1점이면 무조건 0, 평점이 5점이면 무조건 1로 부여)\n"],"metadata":{"id":"5BmIw9l4btTg"}},{"cell_type":"code","source":["import re\n","import urllib.request\n","import zipfile\n","from lxml import etree\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from collections import Counter\n","from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors\n"],"metadata":{"id":"O_3ust5NryMt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1. sentiwordnet에서 뽑힌 모든 단어를 unique하게 리스트업하고, 빈도수 계산 : trigger(counter)"],"metadata":{"id":"nGT9ASudt9nV"}},{"cell_type":"code","source":["u=[] #trigger word가 없는 인덱스를 u에 담음\n","for i in range(len(dfl)):\n","  if type(dfl['sentiwordnet_preds'].iloc[i])!= tuple:\n","    u.append(i)"],"metadata":{"id":"MmVscRiDs7W2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(dfl)):\n","  if i not in u:\n","    dfl['sentiwordnet_points'].iloc[i] = dfl['sentiwordnet_preds'].iloc[i][0]\n","    dfl['sentiwordnet_words'].iloc[i] = dfl['sentiwordnet_preds'].iloc[i][1]"],"metadata":{"id":"Wiw-G17LryKc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all=[]\n","for i in range(len(dfl)):\n","  if i not in u:\n","    all.extend(dfl[\"sentiwordnet_words\"].iloc[i])"],"metadata":{"id":"YmFMybmHrouj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trigger = Counter(all)"],"metadata":{"id":"6ptgWBSfrosm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preprocessing(text):\n","  content_text = re.sub(r'\\([^)]*\\)', '',text)\n","  # 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n","  sent_text = sent_tokenize(content_text)\n","  # 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n","  normalized_text = []\n","  for string in sent_text:\n","      tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n","      normalized_text.append(tokens)\n","  # 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n","  result = [word_tokenize(sentence) for sentence in normalized_text]\n","  return result"],"metadata":{"id":"QuYxQz1wtJC9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.영어 강의평 word2vec 훈련"],"metadata":{"id":"69gBPyFOuD8g"}},{"cell_type":"code","source":["dfl_w2v = dfl[['eng']]\n","dfl_w2v[\"token\"] =0 "],"metadata":{"id":"UHzf3OpdtJEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dfl_w2v[\"token\"] = (dfl_w2v[\"eng\"]).apply( lambda x : preprocessing(x) )"],"metadata":{"id":"gQOzv2K7tJBB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_w2v=[]\n","for i in range(len(dfl_w2v)):\n","  if i not in u:\n","    all_w2v.extend(dfl_w2v[\"token\"].iloc[i])"],"metadata":{"id":"1tEKRZq1tI-x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Word2Vec(sentences=all_w2v, size=100, window=5, min_count=5, workers=4, sg=0)"],"metadata":{"id":"fXO7qR9_tcmW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3. 성적, 로드, 강의력, 교수성향과 관련된 단어 추출"],"metadata":{"id":"jVe2NoYiuNKq"}},{"cell_type":"code","source":["load = model.most_similar(\"load\",topn=50)\n","quality = model.most_similar(\"quality\", topn = 50)\n","scores = model.most_similar(\"scores\",topn = 50)\n","professor = model.most_similar(\"professor\")\n","teach = model.most_similar(\"teach\")\n","teach_df = pd.DataFrame(teach, columns = ['professor_words', 'similarity' ])"],"metadata":{"id":"dz7lCjRCtckf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k= pd.DataFrame(professor, columns = ['professor_words', 'similarity' ])\n","b = pd.DataFrame(quality, columns = ['quality_words', 'similarity' ])\n","c = pd.DataFrame(load, columns = ['load_words', 'similarity' ])\n","d = pd.DataFrame(scores, columns = ['scores_words', 'similarity' ])"],"metadata":{"id":"Hf1NCllYvxt1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["l = pd.concat([k, teach_df], axis =0)\n","l.reset_index(drop=True, inplace=True)\n","trigger_df = pd.concat([l, b,c,d], axis = 1) "],"metadata":{"id":"kwfymDvgwSDk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a1 = trigger_df[['professor_words']]\n","b1 = trigger_df[['load_words']]\n","c1 = trigger_df[['scores_words']]\n","d1 = trigger_df[['quality_words']]"],"metadata":{"id":"PSxa9MiNvwcO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["c1 = trigger_df[['scores_words']]"],"metadata":{"id":"AEoxlmmLwdrB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a1.loc[50,'professor_words']='professor'"],"metadata":{"id":"c6k73JAfwe74"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["load_plus = ['challenge', 'easy' ,'honey']\n","professor_plus =['professor', 'honey', 'difficult', 'assignment','report','honey','god','light']\n","scores_plus = ['quiz','exam','test', 'credit','score','grade']"],"metadata":{"id":"SPWq1ylywl2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["j=0\n","for i in scores_plus:\n","   c1.loc[50+j,'scores_words']= i \n","   j+=1"],"metadata":{"id":"AeDMrGA0whbP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["j=0\n","for i in load_plus:\n","   b1.loc[50+j,'load_words']= i \n","   j+=1"],"metadata":{"id":"58la2Og4whY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["j=0\n","for i in professor_plus:\n","   a1.loc[50+j,'professor_words']= i \n","   j+=1"],"metadata":{"id":"ouFH45SYwhW0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trigger_df['professor_words'] = trigger_df['professor_words'].append(pd.Series(professor_plus),ignore_index=True)"],"metadata":{"id":"OZ3hisr0whUW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 4. trigger list들에 대해 stop word 제거하고 남은 단어들에 대해 3번과 일치하는 값이 존재하면 Y"],"metadata":{"id":"CsLSRbXPuRHr"}},{"cell_type":"code","source":["from nltk.corpus import stopwords \n","from nltk.tokenize import word_tokenize \n","\n","stop_words = set(stopwords.words('english')) \n","\n","\n","result_ = []\n","for token in all: \n","    if token not in stop_words: \n","        result_.append(token) "],"metadata":{"id":"EY5UJ5Whwrt1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_ = []\n","for token in all: \n","    if token not in stop_words: \n","        result_.append(token) "],"metadata":{"id":"pbbxbiGqwsuI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trigger_sw_removed = Counter(result_)"],"metadata":{"id":"YfKBXm86wty2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_set  = set(result_)\n","trigger_pre = list(my_set)"],"metadata":{"id":"muDo-KW9ww_r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_trigger_pre = pd.DataFrame(trigger_pre, columns= [\"word\"])\n","df_trigger_pre[\"similar\"]=0\n","i = 0\n","for j in trigger_pre:\n","    try:\n","      df_trigger_pre[\"similar\"].iloc[i] = model.most_similar(j, topn=20)\n","      i+=1\n","\n","    except KeyError:\n","      print(\"a\")\n","      i+=1"],"metadata":{"id":"JXbCViLRww9c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dfl_d = dfl.drop(u)"],"metadata":{"id":"ax0zuTKlvoAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in dfl_d.index:\n","\n","    if any(word in dfl_d.loc[i,'sentiwordnet_words'] for word in c1 ) : \n","      dfl_d.loc[i,'성적'] = 'Y'\n","    if any(word in dfl_d.loc[i,'sentiwordnet_words'] for word in b1) : \n","      dfl_d.loc[i,'로드'] = 'Y'\n","    if any(word in dfl_d.loc[i,'sentiwordnet_words'] for word in d1) : \n","      dfl_d.loc[i,'강의력'] = 'Y'\n","    if any(word in dfl_d.loc[i,'sentiwordnet_words'] for word in a1) : \n","      dfl_d.loc[i,'교수님성향'] = 'Y'"],"metadata":{"id":"YTNUVF9-tciE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in dfl_d.index:\n","    for word in dfl_d.loc[i,'sentiwordnet_words']:\n","      if word in c1:\n","          dfl_d.loc[i,'성적'] = 'Y'"],"metadata":{"id":"LAGFBBWPvmmN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"5EM74t5Lvp61"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5. Y로 선택된 값은 감성분석 결과를 해당 카테고리의 값으로 부여 "],"metadata":{"id":"6sCCeuHmuUfT"}},{"cell_type":"code","source":["for i in dfl_d.index:\n","  if dfl_d.loc[i,'성적'] == 'Y':     \n","      dfl_d.loc[i,'성적_점수'] = int(dfl_d.loc[i, \"vader_preds\"])\n","  if dfl_d.loc[i,'로드'] == 'Y':     \n","    dfl_d.loc[i,'로드_점수'] = int(dfl_d.loc[i, \"vader_preds\"])\n","  if dfl_d.loc[i,'강의력'] == 'Y':   \n","    dfl_d.loc[i,'강의력_점수'] = int(dfl_d.loc[i, \"vader_preds\"])\n","  if dfl_d.loc[i,'교수님성향'] == 'Y':    \n","    dfl_d.loc[i,'교수님성향_점수'] = int(dfl_d.loc[i, \"vader_preds\"])"],"metadata":{"id":"AvhqX45buURm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dfl_d.to_csv(\"/content/drive/Shareddrives/NLP모델링/코드 연습/예진/allinone.csv\")"],"metadata":{"id":"05VdhRsiuUPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"-wQLyN1ruUNY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6. 최종 점수 부여"],"metadata":{"id":"QIViy2yitIoz"}},{"cell_type":"code","source":["df = pd.read_csv(\"/content/drive/Shareddrives/NLP모델링/코드 연습/예진/allinone.csv\")"],"metadata":{"id":"Ra4ZA80Ab_9k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df[['강의명/교수명', '강의평', 'eng', 'vader_preds',   'sentiwordnet_points', 'sentiwordnet_words']]"],"metadata":{"id":"jGzYqzZKklb2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = df[['학정번호', '강의명/교수명', '별점', 'vader_preds',   'sentiwordnet_points', '강의력_점수', '교수님성향_점수', '로드_점수', '성적_점수']]"],"metadata":{"id":"P_5mu4b0b_5O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["직접 라벨링한 것 0.3 각각을 라벨링한 것 0.7로 가중평균 구한 열 추가 (만약 직접 라벨링이 없으면 직접 라벨링한 값으로 대체하되, 평점이 1점이면 무조건 0, 평점이 5점이면 무조건 1로 부여\n","\n","1. 성적\n","\n","- 후하게 주면 1 후하지 않으면 0 \n","\n","2. 로드 \n","\n","- 쉬우면 1 어려우면 0\n","\n","3. 강의력\n","\n","- 좋으면 1 나쁘면 0\n","\n","4. 교수님 성향\n","\n","- 좋으면 1 나쁘면 0 \n","\n","- 전부다 긍정이 1 부정이 0 중간이 0.5\n","\n","- vader_preds(Y여서 라벨링된 ~_점수열) * 0.7 + hand * 0.3 = final if \n","vader_preds(Y여서 라벨링된 ~_점수열)이 nan이면 hand로\n","\n","- 족보여부와 강의자료질은 직접 라벨링한 결과를 따름"],"metadata":{"id":"BuW-Z1wWcry9"}},{"cell_type":"code","source":["hand = pd.read_csv(\"/content/drive/Shareddrives/NLP모델링/labeling - labeling (1).csv\",encoding='cp949')"],"metadata":{"id":"gaHSpd5xc5Sw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hand = hand[['강의명/교수명', '성적 (너그러움 1, 보통 null, 깐깐함 0)',\n","       '로드 (쉬우면 1, 빡세면 0, 애매하면 null)', '강의력 (좋으면 1, 나쁘면 0)',\n","       '교수님성향 (좋으면 1, 안 좋으면 0)', '족보여부', '강의자료질']]"],"metadata":{"id":"f8Vtq3m1cVBg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hand = hand.fillna(0.5)"],"metadata":{"id":"Qwyaap02fyuj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merge = pd.merge(score,hand, how='inner',on='강의명/교수명')"],"metadata":{"id":"LLmexRJcdol1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["merge = merge.fillna(100) #nan값은 100으로 치환"],"metadata":{"id":"oQEmKeoChteg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(merge)):\n","  if merge.loc[i,'로드_점수']!= 100 :\n","    merge.loc[i,'final_로드'] = merge.loc[i,'로드_점수']*0.7+ merge.loc[i,'로드 (쉬우면 1, 빡세면 0, 애매하면 null)']*0.3\n","  else:\n","    merge.loc[i,'final_로드'] = merge.loc[i,'로드 (쉬우면 1, 빡세면 0, 애매하면 null)']"],"metadata":{"id":"VTj6SFjykoTf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(merge)):\n","  if merge.loc[i,'성적_점수']!= 100 :\n","    merge.loc[i,'final_성적'] = merge.loc[i,'성적_점수']*0.7+ merge.loc[i,'성적 (너그러움 1, 보통 null, 깐깐함 0)']*0.3\n","  else:\n","    merge.loc[i,'final_성적'] = merge.loc[i,'성적 (너그러움 1, 보통 null, 깐깐함 0)']"],"metadata":{"id":"yvnhMvwojc6b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(merge)):\n","  if merge.loc[i,'교수님성향_점수']!= 100 :\n","    merge.loc[i,'final_교수'] = merge.loc[i,'교수님성향_점수']*0.7+ merge.loc[i,'성적 (너그러움 1, 보통 null, 깐깐함 0)']*0.3\n","  else:\n","    merge.loc[i,'final_교수'] = merge.loc[i,'교수님성향 (좋으면 1, 안 좋으면 0)']"],"metadata":{"id":"KbU86GbGj-Vm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(len(merge)):\n","  if merge.loc[i,'강의력_점수']!= 100 :\n","    merge.loc[i,'final_강의력'] = merge.loc[i,'강의력_점수']*0.7+ merge.loc[i,'강의력 (좋으면 1, 나쁘면 0)']*0.3\n","  else:\n","    merge.loc[i,'final_강의력'] = merge.loc[i,'강의력 (좋으면 1, 나쁘면 0)']"],"metadata":{"id":"IQeFf3rykLQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_score = merge[['학정번호', '강의명/교수명', '별점', 'final_성적', 'final_교수',\n","       'final_로드', 'final_강의력','족보여부', '강의자료질']]"],"metadata":{"id":"Wx67euFHlFAM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final_score.to_csv(\"/content/drive/Shareddrives/NLP모델링/코드 연습/예진/final_score.csv\")"],"metadata":{"id":"gZ9XsZ8mi_nX"},"execution_count":null,"outputs":[]}]}